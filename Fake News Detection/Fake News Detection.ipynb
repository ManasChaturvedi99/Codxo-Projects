{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3748eec4",
   "metadata": {},
   "source": [
    "## Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c9baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ade467b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('fake.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45b40b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14431\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for i in df['subject']:\n",
    "    if (i!='News'):\n",
    "        sum+=1\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58764476",
   "metadata": {},
   "source": [
    "## Combine and Shuffle the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd19b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  BENGHAZI WIDOW Hits Back At Hillary’s Heartles...   \n",
      "1  Mali's regional elections delayed by security ...   \n",
      "2  BLACK REPUBLICAN AND BRILLIANT NEUROSURGEON AN...   \n",
      "3  Trump picks Boeing executive Shanahan to becom...   \n",
      "4  HYPOCRISY ON STEROIDS: Check Out HATEFUL Trump...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  Dorothy Woods, the wife of an ex-Navy SEAL kil...      politics   \n",
      "1  BAMAKO (Reuters) - Mali s government said it h...     worldnews   \n",
      "2                                                         politics   \n",
      "3  WASHINGTON (Reuters) - Senior Boeing (BA.N) ex...  politicsNews   \n",
      "4  Lady Gaga, who protested in front of Trump Tow...     left-news   \n",
      "\n",
      "                 date  label  \n",
      "0        Jun 30, 2016      0  \n",
      "1  November 27, 2017       1  \n",
      "2         May 5, 2015      0  \n",
      "3     March 16, 2017       1  \n",
      "4        Jan 14, 2017      0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the datasets\n",
    "fake_df = pd.read_csv('fake.csv')\n",
    "true_df = pd.read_csv('true.csv')\n",
    "\n",
    "# Add a label column to each dataset\n",
    "fake_df['label'] = 0  # Fake news\n",
    "true_df['label'] = 1  # Real news\n",
    "\n",
    "# Combine the datasets\n",
    "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656249c1",
   "metadata": {},
   "source": [
    "## Preprocess The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "875c5cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "823be223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benghazi widow hits back at hillary s heartles...</td>\n",
       "      <td>dorothy woods the wife of an ex navy seal kill...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Jun 30, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>benghazi widow hits back at hillary s heartles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mali s regional elections delayed by security ...</td>\n",
       "      <td>bamako reuters mali s government said it has d...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 27, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>mali s regional elections delayed by security ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black republican and brilliant neurosurgeon an...</td>\n",
       "      <td></td>\n",
       "      <td>politics</td>\n",
       "      <td>May 5, 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>black republican and brilliant neurosurgeon an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump picks boeing executive shanahan to becom...</td>\n",
       "      <td>washington reuters senior boeing ba n executiv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 16, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>trump picks boeing executive shanahan to becom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hypocrisy on steroids check out hateful trump ...</td>\n",
       "      <td>lady gaga who protested in front of trump towe...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jan 14, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>hypocrisy on steroids check out hateful trump ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  benghazi widow hits back at hillary s heartles...   \n",
       "1  mali s regional elections delayed by security ...   \n",
       "2  black republican and brilliant neurosurgeon an...   \n",
       "3  trump picks boeing executive shanahan to becom...   \n",
       "4  hypocrisy on steroids check out hateful trump ...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  dorothy woods the wife of an ex navy seal kill...      politics   \n",
       "1  bamako reuters mali s government said it has d...     worldnews   \n",
       "2                                                         politics   \n",
       "3  washington reuters senior boeing ba n executiv...  politicsNews   \n",
       "4  lady gaga who protested in front of trump towe...     left-news   \n",
       "\n",
       "                 date  label  \\\n",
       "0        Jun 30, 2016      0   \n",
       "1  November 27, 2017       1   \n",
       "2         May 5, 2015      0   \n",
       "3     March 16, 2017       1   \n",
       "4        Jan 14, 2017      0   \n",
       "\n",
       "                                             content  \n",
       "0  benghazi widow hits back at hillary s heartles...  \n",
       "1  mali s regional elections delayed by security ...  \n",
       "2  black republican and brilliant neurosurgeon an...  \n",
       "3  trump picks boeing executive shanahan to becom...  \n",
       "4  hypocrisy on steroids check out hateful trump ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets clean the dataset to remove any special characters\n",
    "## extra space and also convert all text into lower case.\n",
    "\n",
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in square brackets\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r\"\\'\", \"'\", text)  # Handle special characters\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "df['title'] = df['title'].apply(clean_text)\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Combine title and text\n",
    "df['content'] = df['title'] + ' ' + df['text']\n",
    "\n",
    "# Display the first few rows of the combined dataset with cleaned text\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c401d66",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46d3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75def883",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082ec9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data into train and test.\n",
    "## using tfdfvectorizer for converting the text into numerical features\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['content']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15b197",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34047eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9906\n",
      "Precision: 0.9875\n",
      "Recall: 0.9927\n",
      "F1-score: 0.9901\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4758\n",
      "           1       0.99      0.99      0.99      4222\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Train the model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddcdb8",
   "metadata": {},
   "source": [
    "## Model Testing with user input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b338f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fakenews.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Assuming rf_model is your RandomForestClassifier model\n",
    "dump(lr_model, 'fakenews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01aba2ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 13 features, but LogisticRegression is expecting 5000 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124mbenghazi widow hits back at hillary s heartles...\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Predict using the model\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_fake_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mpredict_fake_news\u001b[1;34m(input_text, model)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_fake_news\u001b[39m(input_text, model):\n\u001b[0;32m     23\u001b[0m     processed_text \u001b[38;5;241m=\u001b[39m preprocess_input(input_text)\n\u001b[1;32m---> 24\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_text\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFake News\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:332\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    329\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 13 features, but LogisticRegression is expecting 5000 features as input."
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in square brackets\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r\"\\'\", \"'\", text)  # Handle special characters\n",
    "    return text\n",
    "\n",
    "# Function to preprocess input for prediction\n",
    "def preprocess_input(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    combined_text = cleaned_text  # Assuming input is already combined title and text\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    tfidf_text = tfidf_vectorizer.fit_transform([combined_text])\n",
    "    return tfidf_text\n",
    "\n",
    "# Function to predict using the loaded model\n",
    "def predict_fake_news(input_text, model):\n",
    "    processed_text = preprocess_input(input_text)\n",
    "    prediction = model.predict(processed_text)[0]\n",
    "    if prediction == 0:\n",
    "        return \"Fake News\"\n",
    "    else:\n",
    "        return \"Real News\"\n",
    "\n",
    "# Example user input\n",
    "user_input = \"\"\"\n",
    "benghazi widow hits back at hillary s heartles...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Predict using the model\n",
    "prediction = predict_fake_news(user_input, lr_model)\n",
    "print(f'Prediction: {prediction}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
